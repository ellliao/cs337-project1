{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f073ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "# from nltk.tokenize import sent_tokenize, word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "919bad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_processed_tweets_from_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "data = load_processed_tweets_from_json(\"gg2013_preprocessed.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_retweet_text(text):\n",
    "    \"\"\"Removes the 'rt @username:' prefix from a retweet, leaving only the main content.\"\"\"\n",
    "    # Check if the text starts with 'rt @'\n",
    "    if text.startswith(\"rt @\"):\n",
    "        # Find the position of the first colon after 'rt @username'\n",
    "        colon_position = text.find(\":\")\n",
    "        # If a colon exists, return the text after it; otherwise, return the full string\n",
    "        if colon_position != -1:\n",
    "            return text[colon_position + 1:].strip()\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b904ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['best supporting actor in a motion picture', ' christoph waltz ']\n",
      "['best supporting actor in a motion picture - comedy or picture', ' christoph waltz ']\n",
      "['best supporting actor in a motion picture', ' christoph waltz']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\18723\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "nltk.download('words')\n",
    "\n",
    "award_name_allowlist = [\"drama\", \"musical\", \"comedy\", \"animated\", \"animation\", \"motion\", \"television\", \"series\"]\n",
    "\n",
    "def extract_award_name(sentence):\n",
    "    \"\"\"Extracts the award name and winner from the sentence based on specified conditions.\"\"\"\n",
    "    # Find all hyphen and colon positions\n",
    "    split_positions = [i for i, char in enumerate(sentence) if char in \"-:\"]\n",
    "    award_name = None\n",
    "    winner = None\n",
    "\n",
    "    for index, pos in enumerate(split_positions):\n",
    "        # Split the sentence at the current hyphen/colon position\n",
    "\n",
    "        if index >= 1:\n",
    "            left_part = sentence[split_positions[index - 1] + 1: split_positions[index]].strip()\n",
    "        else:\n",
    "            left_part = sentence[:pos].strip()\n",
    "        right_part = sentence[pos + 1:].strip()\n",
    "\n",
    "        # Check if there's something on the right\n",
    "        if not right_part:\n",
    "            return award_name, winner\n",
    "\n",
    "        # Split left part into words\n",
    "        left_words = left_part.split()\n",
    "\n",
    "        # Check for \"best\" or \"award\" in left part\n",
    "        if any(word.lower() in left_words for word in ['best', 'award']):\n",
    "\n",
    "            # Determine the right portion based on allowlist keywords\n",
    "            if index < len(split_positions) - 1:\n",
    "                next_segment = sentence[pos + 1:split_positions[index + 1]].strip()\n",
    "            else:\n",
    "                next_segment = right_part\n",
    "\n",
    "            # Assign award name and winner based on allowlist\n",
    "            if any(word.lower() in next_segment.lower() for word in award_name_allowlist):\n",
    "                award_name = f\"{left_part} - {next_segment}\".strip()\n",
    "                # Capture the winner if more splits remain\n",
    "                if index < len(split_positions) - 2:\n",
    "                    winner = sentence[split_positions[index + 1] + 1: split_positions[index + 2]].strip()\n",
    "            else:\n",
    "                award_name = left_part\n",
    "                winner = next_segment\n",
    "            break\n",
    "\n",
    "    return [award_name, winner]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d65961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_winner_info(sentence):\n",
    "    \"\"\"Check if the sentence is in the format '... wins ...' with 'best' or 'award' in the second part.\"\"\"\n",
    "\n",
    "    pattern = r'^(.*?)(wins|receives)(.*?)(best|award)(.*?)$'\n",
    "    match = re.search(pattern, sentence, re.IGNORECASE)\n",
    "\n",
    "    if match:\n",
    "\n",
    "        first_part = match.group(1).strip()\n",
    "        second_part = match.group(3).strip() + \" \" + match.group(\n",
    "            4).strip()  + match.group(5).strip()\n",
    "        return [first_part, second_part]\n",
    "\n",
    "    return []\n",
    "\n",
    "def get_combinations(input_string):\n",
    "   \n",
    "    words = input_string.split()\n",
    "    combinations = []\n",
    "    \n",
    "    \n",
    "\n",
    "    for j in range(1, len(words) + 1):\n",
    "        \n",
    "        combinations.append(' '.join(words[0:j]))\n",
    "    \n",
    "    return combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "330855f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, tweet in enumerate(data):\n",
    "    \n",
    "    tweet_text = tweet['text']\n",
    "    \n",
    "    award_name = extract_winner_info(tweet_text)\n",
    "    \n",
    "    if award_name:\n",
    "        win_resolutions = {\n",
    "            \"award\" : get_combinations(award_name[1]),\n",
    "            \"winner\": [award_name[0]],\n",
    "            \"confidence\": 0.7\n",
    "            \n",
    "        }\n",
    "        tweet[\"win_resolutions\"] = win_resolutions\n",
    "        \n",
    "        continue\n",
    "    award_name = extract_award_name(tweet_text)\n",
    "    \n",
    "    if award_name:\n",
    "        win_resolutions = {\n",
    "            \"award\" : get_combinations(award_name[0]),\n",
    "            \"winner\": [award_name[1]],\n",
    "            \"confidence\": 0.5\n",
    "            \n",
    "        }\n",
    "        tweet[\"win_resolutions\"] = win_resolutions\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "011d343b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: blis in c:\\users\\18723\\anaconda3\\lib\\site-packages (1.0.1)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\18723\\\\AppData\\\\Local\\\\Temp\\\\pip-uninstall-lyo0f3pl\\\\numpy\\\\linalg\\\\_umath_linalg.cp311-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting numpy<3.0.0,>=2.0.0 (from blis)\n",
      "  Using cached numpy-2.1.2-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n"
     ]
    }
   ],
   "source": [
    "%pip install blis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd864880",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d036e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def get_part_before_host(sentence):\n",
    "    # pattern to capture only the part before the hosting-related verbs\n",
    "    pattern = r\"(.*?)(?:\\s+(?:is|are)\\s+)?(?:hosts|host|are hosting|is hosting)\"\n",
    "\n",
    "    \n",
    "    match = re.search(pattern, sentence, re.IGNORECASE)\n",
    "\n",
    "    if match:\n",
    "        # Return the part before the hosting verb\n",
    "        return match.group(1).strip()\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_hosts_from_text(text):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "\n",
    "    hosts = []\n",
    "\n",
    "    for sentence in doc.sents:\n",
    "\n",
    "\n",
    "        # Find the root verb of the sentence\n",
    "        root_verb = [token for token in sentence if token.dep_ == \"ROOT\"]\n",
    "\n",
    "        if root_verb and root_verb[0].lemma_ == \"host\":\n",
    "            # Get the part before the hosting verb using regex function\n",
    "            sentence_text = str(sentence)\n",
    "            before_host = get_part_before_host(sentence_text)\n",
    "\n",
    "            if before_host:\n",
    "                # Split the part by \"and\" or \"&\" to extract multiple hosts\n",
    "                \n",
    "                potential_hosts = re.split(r'\\s*(?:and|&|/|\\\\)\\s*', before_host)\n",
    "\n",
    "                hosts.extend(potential_hosts)\n",
    "\n",
    "    return hosts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da3f9f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, tweet in enumerate(data):\n",
    "    \n",
    "    tweet_text = tweet['text']\n",
    "    \n",
    "    \n",
    "    hosts = find_hosts_from_text(tweet_text)\n",
    "    \n",
    "    if hosts:\n",
    "        host_resolutions = {\n",
    "            \"hosts\": hosts,\n",
    "            \"confidence\": 0.7\n",
    "            \n",
    "            \n",
    "        }\n",
    "        tweet[\"host_resolutions\"] = host_resolutions\n",
    "        \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'parsed_data.json'\n",
    "\n",
    "# Write data to JSON file\n",
    "with open(filename, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
