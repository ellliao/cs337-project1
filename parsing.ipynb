{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "02f073ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "# from nltk.tokenize import sent_tokenize, word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "919bad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_processed_tweets_from_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "data = load_processed_tweets_from_json(\"gg2013_preprocessed.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3dad3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_retweet_text(text):\n",
    "    \"\"\"Removes the 'rt @username:' prefix from a retweet, leaving only the main content.\"\"\"\n",
    "    # Check if the text starts with 'rt @'\n",
    "    if text.startswith(\"rt @\"):\n",
    "        # Find the position of the first colon after 'rt @username'\n",
    "        colon_position = text.find(\":\")\n",
    "        # If a colon exists, return the text after it; otherwise, return the full string\n",
    "        if colon_position != -1:\n",
    "            return text[colon_position + 1:].strip()\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "38b904ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import re\n",
    "\n",
    "award_name_allowlist = [\"drama\", \"musical\", \"comedy\", \"animated\", \"animation\", \"motion\", \"television\", \"series\", \"award\", \"best\"]\n",
    "\n",
    "def extract_award_name(sentence):\n",
    "    \"\"\"Extracts the award name and winner from the sentence based on specified conditions.\"\"\"\n",
    "    # Find all hyphen and colon positions\n",
    "    split_positions = [i for i, char in enumerate(sentence) if char in \"-:\"]\n",
    "    award_name = None\n",
    "    winner = None\n",
    "    \n",
    "    if not re.search(r'[-:]', sentence):\n",
    "        return [None, None]  # Return None if there is no hyphen or colon\n",
    "\n",
    "        # Step 2: Check if sentence contains \"best\" (case insensitive)\n",
    "    if \"best\" not in sentence.lower():\n",
    "        return [None, None]  # Return None if \"best\" is not present\n",
    "\n",
    "    for index, pos in enumerate(split_positions):\n",
    "        # Split the sentence at the current hyphen/colon position\n",
    "\n",
    "        if index >= 1:\n",
    "            left_part = sentence[split_positions[index - 1] + 1: split_positions[index]].strip()\n",
    "        else:\n",
    "            left_part = sentence[:pos].strip()\n",
    "        right_part = sentence[pos + 1:].strip()\n",
    "\n",
    "        # Check if there's something on the right\n",
    "        if not right_part:\n",
    "            return award_name, winner\n",
    "\n",
    "        # Split left part into words\n",
    "        left_words = left_part.split()\n",
    "\n",
    "        # Check for \"best\" or \"award\" in left part\n",
    "        if any(word.lower() in left_words for word in ['best', 'award']):\n",
    "\n",
    "            # Determine the right portion based on allowlist keywords\n",
    "            if index < len(split_positions) - 1:\n",
    "                next_segment = sentence[pos + 1:split_positions[index + 1]].strip()\n",
    "            else:\n",
    "                next_segment = right_part\n",
    "\n",
    "            # Assign award name and winner based on allowlist\n",
    "            if any(word.lower() in next_segment.lower() for word in award_name_allowlist):\n",
    "                award_name = f\"{left_part} - {next_segment}\".strip()\n",
    "                # Capture the winner if more splits remain\n",
    "                if index < len(split_positions) - 2:\n",
    "                    winner = sentence[split_positions[index + 1] + 1: split_positions[index + 2]].strip()\n",
    "            else:\n",
    "                award_name = left_part\n",
    "                winner = next_segment\n",
    "            break\n",
    "    if winner and '.' in winner:\n",
    "        winner = re.split(r'\\.', winner, 1)[0].strip()\n",
    "\n",
    "    return [award_name, winner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4d65961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_winner_info(text):\n",
    "    \"\"\"Check if the sentence contains a pattern like '... wins ...' with 'best' or 'award' in the second part.\"\"\"\n",
    "    text = clean_retweet_text(text)\n",
    "    \n",
    "    pattern = r'^(.*?)(wins|receives)(.*?)(best)(.*?)$'\n",
    "    \n",
    "    # Split the text into sentences\n",
    "    sentences = re.split(r'[.!?]', text)\n",
    "    \n",
    "    # Check each sentence individually\n",
    "    for sentence in sentences:\n",
    "        match = re.search(pattern, sentence.strip(), re.IGNORECASE)\n",
    "        \n",
    "        if match:\n",
    "            # Extract parts based on the match\n",
    "            first_part = match.group(1).strip()\n",
    "            second_part = match.group(3).strip() + \" \" + match.group(4).strip() + \" \" + match.group(5).strip()\n",
    "            \n",
    "            return [first_part, second_part]\n",
    "    \n",
    "    \n",
    "    return None\n",
    "\n",
    "def extract_award_sequences(input_str):\n",
    "    \n",
    "    initial_pattern = r\"(?i)^(?:golden globes for|golden globes|award for)\\s+(best)\\s+(.+)\"\n",
    "    match = re.search(initial_pattern, input_str)\n",
    "    if match:\n",
    "        input_str = match.group(1) + \" \" + match.group(2)\n",
    "        \n",
    "\n",
    "    \n",
    "    refine_pattern = r\"(?i)(best|award)\\s+(.+?)(?:\\s+golden globes|goldenglobes|$)\"\n",
    "    match = re.search(refine_pattern, input_str)\n",
    "    if match:\n",
    "        input_str = match.group(1) + \" \" + match.group(2).strip()\n",
    "\n",
    "    \n",
    "    split_parts = re.split(r'(\\s*-\\s*|\\s+for\\s+)', input_str) \n",
    "    sequences = []\n",
    "    current_sequence = split_parts[0].strip()\n",
    "\n",
    "    \n",
    "    for i in range(1, len(split_parts) - 1, 2):\n",
    "        sequences.append(current_sequence) \n",
    "        separator = split_parts[i].strip() \n",
    "        next_part = split_parts[i + 1].strip()\n",
    "        current_sequence += f\" {separator} {next_part}\" \n",
    "\n",
    "    sequences.append(current_sequence)  \n",
    "\n",
    "    return sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "330855f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, tweet in enumerate(data):\n",
    "    \n",
    "    tweet_text = tweet['text']\n",
    "    tweet_text = clean_retweet_text(tweet_text)\n",
    "    \n",
    "    award_name = extract_winner_info(tweet_text)\n",
    "    \n",
    "    if award_name:\n",
    "        win_resolutions = {\n",
    "            \"award\" : extract_award_sequences(award_name[1]),\n",
    "            \"winner\": [award_name[0]],\n",
    "            \"confidence\": 0.7\n",
    "            \n",
    "        }\n",
    "        tweet[\"win_resolutions\"] = win_resolutions\n",
    "        \n",
    "        continue\n",
    "    award_name = extract_award_name(tweet_text)\n",
    "    \n",
    "    if award_name[0]:\n",
    "        win_resolutions = {\n",
    "            \"award\" : extract_award_sequences(award_name[0]),\n",
    "            \"winner\": [award_name[1]],\n",
    "            \"confidence\": 0.8\n",
    "            \n",
    "        }\n",
    "        tweet[\"win_resolutions\"] = win_resolutions\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "011d343b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: blis in c:\\users\\18723\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=2.0.0 in c:\\users\\18723\\anaconda3\\lib\\site-packages (from blis) (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install blis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "98ac428f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in c:\\users\\18723\\anaconda3\\lib\\site-packages (1.0.9)\n",
      "Requirement already satisfied: six in c:\\users\\18723\\anaconda3\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fd864880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "                                              0.0/12.8 MB ? eta -:--:--\n",
      "                                              0.1/12.8 MB 1.7 MB/s eta 0:00:08\n",
      "                                              0.2/12.8 MB 2.1 MB/s eta 0:00:07\n",
      "                                              0.3/12.8 MB 2.2 MB/s eta 0:00:06\n",
      "     -                                        0.4/12.8 MB 2.2 MB/s eta 0:00:06\n",
      "     -                                        0.4/12.8 MB 1.9 MB/s eta 0:00:07\n",
      "     -                                        0.5/12.8 MB 1.8 MB/s eta 0:00:08\n",
      "     -                                        0.5/12.8 MB 1.8 MB/s eta 0:00:07\n",
      "     -                                        0.6/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "     -                                        0.6/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "     --                                       0.7/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "     --                                       0.8/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "     --                                       0.9/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "     ---                                      1.0/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     ---                                      1.1/12.8 MB 1.7 MB/s eta 0:00:08\n",
      "     ---                                      1.1/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     ---                                      1.3/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     ----                                     1.4/12.8 MB 1.8 MB/s eta 0:00:07\n",
      "     ----                                     1.5/12.8 MB 1.8 MB/s eta 0:00:07\n",
      "     -----                                    1.6/12.8 MB 1.9 MB/s eta 0:00:07\n",
      "     -----                                    1.8/12.8 MB 1.9 MB/s eta 0:00:06\n",
      "     -----                                    1.9/12.8 MB 2.0 MB/s eta 0:00:06\n",
      "     ------                                   2.1/12.8 MB 2.1 MB/s eta 0:00:06\n",
      "     ------                                   2.2/12.8 MB 2.1 MB/s eta 0:00:06\n",
      "     -------                                  2.4/12.8 MB 2.2 MB/s eta 0:00:05\n",
      "     --------                                 2.6/12.8 MB 2.2 MB/s eta 0:00:05\n",
      "     --------                                 2.7/12.8 MB 2.3 MB/s eta 0:00:05\n",
      "     ---------                                2.9/12.8 MB 2.3 MB/s eta 0:00:05\n",
      "     ---------                                3.1/12.8 MB 2.4 MB/s eta 0:00:05\n",
      "     ----------                               3.2/12.8 MB 2.4 MB/s eta 0:00:04\n",
      "     ----------                               3.4/12.8 MB 2.5 MB/s eta 0:00:04\n",
      "     -----------                              3.6/12.8 MB 2.5 MB/s eta 0:00:04\n",
      "     -----------                              3.8/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ------------                             3.9/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ------------                             4.1/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     -------------                            4.2/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     -------------                            4.4/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "     --------------                           4.5/12.8 MB 2.7 MB/s eta 0:00:04\n",
      "     --------------                           4.7/12.8 MB 2.7 MB/s eta 0:00:04\n",
      "     ---------------                          5.0/12.8 MB 2.8 MB/s eta 0:00:03\n",
      "     ---------------                          5.1/12.8 MB 2.8 MB/s eta 0:00:03\n",
      "     ----------------                         5.3/12.8 MB 2.8 MB/s eta 0:00:03\n",
      "     -----------------                        5.5/12.8 MB 2.8 MB/s eta 0:00:03\n",
      "     ------------------                       5.8/12.8 MB 2.9 MB/s eta 0:00:03\n",
      "     ------------------                       5.9/12.8 MB 2.9 MB/s eta 0:00:03\n",
      "     -------------------                      6.1/12.8 MB 2.9 MB/s eta 0:00:03\n",
      "     -------------------                      6.3/12.8 MB 3.0 MB/s eta 0:00:03\n",
      "     --------------------                     6.5/12.8 MB 3.0 MB/s eta 0:00:03\n",
      "     ---------------------                    6.7/12.8 MB 3.0 MB/s eta 0:00:03\n",
      "     ---------------------                    7.0/12.8 MB 3.1 MB/s eta 0:00:02\n",
      "     ----------------------                   7.2/12.8 MB 3.1 MB/s eta 0:00:02\n",
      "     -----------------------                  7.5/12.8 MB 3.2 MB/s eta 0:00:02\n",
      "     ------------------------                 7.8/12.8 MB 3.3 MB/s eta 0:00:02\n",
      "     -------------------------                8.0/12.8 MB 3.3 MB/s eta 0:00:02\n",
      "     -------------------------                8.2/12.8 MB 3.3 MB/s eta 0:00:02\n",
      "     --------------------------               8.4/12.8 MB 3.3 MB/s eta 0:00:02\n",
      "     --------------------------               8.6/12.8 MB 3.3 MB/s eta 0:00:02\n",
      "     ---------------------------              8.9/12.8 MB 3.4 MB/s eta 0:00:02\n",
      "     ----------------------------             9.0/12.8 MB 3.4 MB/s eta 0:00:02\n",
      "     ----------------------------             9.3/12.8 MB 3.4 MB/s eta 0:00:02\n",
      "     -----------------------------            9.5/12.8 MB 3.4 MB/s eta 0:00:01\n",
      "     ------------------------------           9.8/12.8 MB 3.5 MB/s eta 0:00:01\n",
      "     -------------------------------          10.0/12.8 MB 3.5 MB/s eta 0:00:01\n",
      "     --------------------------------         10.3/12.8 MB 3.5 MB/s eta 0:00:01\n",
      "     --------------------------------         10.4/12.8 MB 3.6 MB/s eta 0:00:01\n",
      "     ---------------------------------        10.6/12.8 MB 3.6 MB/s eta 0:00:01\n",
      "     ---------------------------------        10.8/12.8 MB 3.9 MB/s eta 0:00:01\n",
      "     ----------------------------------       11.1/12.8 MB 4.0 MB/s eta 0:00:01\n",
      "     -----------------------------------      11.4/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     ------------------------------------     11.7/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     ------------------------------------     11.8/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     -------------------------------------    12.2/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     --------------------------------------   12.5/12.8 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 4.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 4.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 4.5 MB/s eta 0:00:00\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d036e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from langdetect import detect, DetectorFactory\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "def find_people_from_text(text):\n",
    "\n",
    "    # Skip if not English\n",
    "    try:\n",
    "        if detect(text) != 'en':\n",
    "            return {}\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "    doc = nlp(text)\n",
    "    confidence = 0.5\n",
    "\n",
    "    # Find the people mentioned in the tweet\n",
    "    potential_hosts = [entity for entity in doc.ents \\\n",
    "                           if entity.label_ == \"PERSON\"]\n",
    "    # Add to hosts\n",
    "    hosts =[host.text for host in potential_hosts]\n",
    "\n",
    "    for sentence in doc.sents:\n",
    "        \n",
    "        # Find the root verb of the sentence\n",
    "        root_verb = [token for token in sentence if token.dep_ == \"ROOT\"]\n",
    "\n",
    "        if root_verb and root_verb[0].lemma_ == \"host\":\n",
    "            confidence = 0.7\n",
    "            break\n",
    "\n",
    "    return {'hosts': hosts, 'confidence': confidence}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "da3f9f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "have_host_resolutions = []\n",
    "for index, tweet in enumerate(data):\n",
    "    \n",
    "    tweet_text = tweet['text']\n",
    "    \n",
    "    # Skip if no mention of host in text, or about next year\n",
    "    if re.search(r'(?:\\bhost)|(?:host(?:s|ed|ing)?\\b)', tweet_text, re.IGNORECASE) == None \\\n",
    "        or re.search(r'\\bnext\\b', tweet_text, re.IGNORECASE) != None:\n",
    "        host_resolutions = {}\n",
    "    else:\n",
    "        host_resolutions = find_people_from_text(tweet_text)\n",
    "    \n",
    "    if host_resolutions:\n",
    "        have_host_resolutions.append(index)\n",
    "        tweet[\"host_resolutions\"] = host_resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f80ee0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string_on_and(text: str):\n",
    "    # Split the text by \"and\" or \"&\" with surrounding whitespace handling\n",
    "    parts = re.split(r'\\s*(?:\\band\\b|&)\\s*', text)\n",
    "    # Filter out any empty strings in the list\n",
    "    return [part.strip() for part in parts if part.strip()]\n",
    "\n",
    "def parse_presenters(tweet: str):\n",
    "    # Define the regex pattern to match the presenters and award pattern\n",
    "    pattern = r\"(.*?)(?<!re)(?:\\bpresent\\b|\\bpresents\\b|\\bpresenting\\b|\\bpresenting for\\b)\\s+(.*?(?:best).*)\"\n",
    "    \n",
    "    # Split the tweet into sentences\n",
    "    sentences = re.split(r'[.!?]', tweet)\n",
    "    \n",
    "    # Check each sentence individually\n",
    "    for sentence in sentences:\n",
    "        match = re.search(pattern, sentence.strip(), re.IGNORECASE)\n",
    "        \n",
    "        if match:\n",
    "            # Extract the presenters and award from the match\n",
    "            presenters = match.group(1).strip()\n",
    "            award = match.group(2).strip()\n",
    "\n",
    "            # Clean the award string\n",
    "            # Remove any words before \"best\"\n",
    "            award = re.sub(r\".*?\\bbest\\b\", \"best\", award, flags=re.IGNORECASE)\n",
    "            # Remove any words including and after \"at,\" \"and,\" \"for,\" or \"to\"\n",
    "            award = re.sub(r\"\\s+\\b(at|and|for|to)\\b.*\", \"\", award, flags=re.IGNORECASE)\n",
    "            \n",
    "            return [award.strip(),   split_string_on_and(presenters)]\n",
    "    \n",
    "    \n",
    "    return [None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a5070413",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, tweet in enumerate(data):\n",
    "    \n",
    "    tweet_text = tweet['text']\n",
    "    tweet_text = clean_retweet_text(tweet_text)\n",
    "    \n",
    "    \n",
    "    possible_presenters  = parse_presenters(tweet_text)\n",
    "    if possible_presenters[0]:\n",
    "      present_resolutions = {\"award\": possible_presenters[0], \"presenters\": possible_presenters[1], \"confidence\": 0.7}\n",
    "      tweet[\"present_resolutions\"] = present_resolutions\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d129aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nominees(text: str):\n",
    "    # Define the regex pattern to match \"nominee/nominated/nominees ... ... best\"\n",
    "    pattern = r\"(.*)\\b(?:nominee|nominated|nominees)\\b(.*?\\bbest\\b.*)\"\n",
    "    # Define a list of exclusion words/phrases\n",
    "    exclusions = r\"\\b(?:not|should've|should have|wasn't|introduce|present|should)\\b\"\n",
    "\n",
    "    # Split the text into sentences\n",
    "    sentences = re.split(r'[.!?]', text)\n",
    "\n",
    "    # Check each sentence individually\n",
    "    for sentence in sentences:\n",
    "        # Check if any exclusion word is present\n",
    "        if re.search(exclusions, sentence, re.IGNORECASE):\n",
    "            continue\n",
    "\n",
    "        \n",
    "        match = re.search(pattern, sentence, re.IGNORECASE)\n",
    "        if match:\n",
    "            # Clean and separate the nominee part and award name\n",
    "            before_nominee = re.sub(r\"\\b(?:nominee|nominated|nominees)\\b\", \"\", match.group(1), flags=re.IGNORECASE).strip()\n",
    "            award_name = re.sub(r\".*?\\bbest\\b\", \"best\", match.group(2), flags=re.IGNORECASE).strip()\n",
    "\n",
    "            return [before_nominee, award_name]\n",
    "\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cc071a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nominees2(text: str) :\n",
    "    # Define the regex pattern to match a sentence with a negative word, \"win/won,\" and \"best\"\n",
    "    pattern = r\"(.*?)(\\bdoes not\\b|\\bnot\\b|\\bshould have\\b|\\bshould've\\b|\\bshould\\b|\\bdidn't\\b|\\bdid not\\b)(.*?\\b(?:win|won)\\b.*?\\bbest\\b.*)\"\n",
    "\n",
    "    # Split the text into sentences\n",
    "    sentences = re.split(r'[.:!?]', text)\n",
    "\n",
    "    # Process each sentence individually\n",
    "    for sentence in sentences:\n",
    "        match = re.search(pattern, sentence.strip(), re.IGNORECASE)\n",
    "\n",
    "        if match:\n",
    "            # Extract the part before the negative word as the nominee\n",
    "            nominee = match.group(1).strip()\n",
    "            # Extract the part from \"best\" onward as the award_name\n",
    "            award_name = re.sub(r\".*?\\bbest\\b\", \"best\", match.group(3), flags=re.IGNORECASE).strip()\n",
    "\n",
    "            # Clean the nominee by removing text before and including \"that\" or \"if\"\n",
    "            nominee = re.sub(r\".*\\b(that|if)\\b\", \"\", nominee, flags=re.IGNORECASE).strip()\n",
    "\n",
    "            return [nominee, award_name]\n",
    "\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3af3bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, tweet in enumerate(data):\n",
    "    \n",
    "    tweet_text = tweet['text']\n",
    "    tweet_text = clean_retweet_text(tweet_text)\n",
    "    \n",
    "    \n",
    "    possible_nominee  = get_nominees(tweet_text)\n",
    "    if possible_nominee:\n",
    "    \n",
    "\n",
    "        nominee_resolutions = {\"award\": possible_nominee[1], \"nominee\": possible_presenters[0], \"confidence\": 0.5}\n",
    "        tweet[\"nominee_resolutions\"] = nominee_resolutions\n",
    "        \n",
    "    possible_nominee  = get_nominees2(tweet_text)\n",
    "    if possible_nominee:\n",
    "    \n",
    "\n",
    "        nominee_resolutions = {\"award\": possible_nominee[1], \"nominee\": possible_presenters[0], \"confidence\": 0.5}\n",
    "        tweet[\"nominee_resolutions\"] = nominee_resolutions\n",
    "      \n",
    "      \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fc20494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'parsed_data.json'\n",
    "\n",
    "# Write data to JSON file\n",
    "with open(filename, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
